{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebc10ba",
   "metadata": {},
   "source": [
    "# Collect dataset from Dossier-Facile\n",
    "\n",
    "1) find 100 random validated tax notice documents (with 1 page for now, to make the task a bit easier) by run this query in metabase \n",
    "\n",
    "```sql\n",
    "SELECT file_id\n",
    "FROM dbt_prod.core_file \n",
    "WHERE document_category='TAX' \n",
    "  AND document_sub_category = 'MY_NAME'\n",
    "  AND document_status = 'VALIDATED'\n",
    "  AND page_number = 1\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 10000;\n",
    "```\n",
    "\n",
    "download to csv on metabase and place it in datasets/2d-doc/tax-notices.csv\n",
    "\n",
    "**Note:** we download a lot of files because they will be filtered: many files does not contain 2d-doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def load_tax_notice_dataset(csv_path: str = \"../../datasets/2d-doc/tax-notices.csv\") -> List[str]:\n",
    "    df = pd.read_csv(csv_path, usecols=[\"file_id\"])\n",
    "    ids = df[\"file_id\"].dropna().astype(str).str.strip()\n",
    "    return [s for s in ids.tolist() if s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07e9be",
   "metadata": {},
   "source": [
    "# download files\n",
    "\n",
    "you need to get JSESSIONID cookie from dossier facile back office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdc044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv('../../.env')\n",
    "\n",
    "def get_tax_notice_image(file_id):\n",
    "    \"\"\"\n",
    "    Fetch a file from DossierFacile and return it as a PIL Image.\n",
    "    \n",
    "    Args:\n",
    "        file_id: The file identifier (e.g., \"xx xxx xxx\")\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image: The loaded image\n",
    "    \"\"\"\n",
    "    cookies = {'JSESSIONID': os.getenv(\"DOSSIER_FACILE_JSESSIONID\")}\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'}\n",
    "    \n",
    "    url = f'https://bo.dossierfacile.fr/files/{file_id}'\n",
    "    response = requests.get(url, cookies=cookies, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    content_type = response.headers.get('content-type', '').lower()\n",
    "    \n",
    "    if 'pdf' in content_type:\n",
    "        doc = fitz.open(stream=response.content, filetype='pdf')\n",
    "        page = doc.load_page(0)\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes('RGB', (pix.width, pix.height), pix.samples)\n",
    "        doc.close()\n",
    "        return img\n",
    "    \n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df92b06",
   "metadata": {},
   "source": [
    "# extract data\n",
    "\n",
    "find extract 2d-doc data using libdmtx, parse content using https://github.com/nipo/tdd -> \n",
    "clone and run `cd tdd; pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27672c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pylibdmtx.pylibdmtx import decode\n",
    "from tdd.doc import TwoDDoc\n",
    "\n",
    "\n",
    "class TaxNoticeData(BaseModel):\n",
    "    \"\"\"Tax notice data extracted from 2D-DOC\"\"\"\n",
    "    doc_type: Optional[str] = None\n",
    "    emitter_type: Optional[str] = None\n",
    "    \n",
    "    # Dataset fields with English names\n",
    "    number_of_shares: Optional[str] = Field(None, description=\"Nombre de parts\")\n",
    "    tax_notice_reference: Optional[str] = Field(None, description=\"Référence d'avis d'impôt\")\n",
    "    income_year: Optional[str] = Field(None, description=\"Année des revenus\")\n",
    "    declarant_1: Optional[str] = Field(None, description=\"Déclarant 1\")\n",
    "    collection_date: Optional[str] = Field(None, description=\"Date de mise en recouvrement\")\n",
    "    tax_number_declarant_1: Optional[str] = Field(None, description=\"Numéro fiscal du déclarant 1\")\n",
    "    reference_tax_income: Optional[str] = Field(None, description=\"Revenu fiscal de référence\")\n",
    "\n",
    "\n",
    "def extract_tax_notice(pil_image: Image.Image, timeout=5000) -> Optional[TaxNoticeData]:\n",
    "    \"\"\"\n",
    "    Extract tax notice information from a PIL Image containing a DataMatrix code.\n",
    "    \n",
    "    Args:\n",
    "        pil_image: PIL Image object containing a DataMatrix code\n",
    "        \n",
    "    Returns:\n",
    "        TaxNoticeData object with extracted information, or None if no code found\n",
    "        \n",
    "    Example:\n",
    "        >>> from PIL import Image\n",
    "        >>> img = Image.open(\"avis-imposition.jpeg\")\n",
    "        >>> result = extract_tax_notice(img)\n",
    "        >>> if result:\n",
    "        ...     print(f\"Reference: {result.tax_notice_reference}\")\n",
    "        ...     print(f\"Income: {result.reference_tax_income}\")\n",
    "    \"\"\"\n",
    "    # Convert PIL Image to numpy array\n",
    "    img_array = np.array(pil_image)\n",
    "    \n",
    "    # Convert to BGR if needed (OpenCV uses BGR)\n",
    "    if len(img_array.shape) == 3:\n",
    "        if img_array.shape[2] == 4:  # RGBA\n",
    "            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)\n",
    "        elif img_array.shape[2] == 3:  # RGB\n",
    "            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    if len(img_array.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img_array\n",
    "    \n",
    "    # Decode DataMatrix\n",
    "    res = decode(gray, max_count=2, timeout=timeout)\n",
    "    \n",
    "    if not res:\n",
    "        return None\n",
    "    \n",
    "    doc = None\n",
    "    # Parse 2D-DOC\n",
    "    for potential_doc in res:\n",
    "        try:\n",
    "            raw_data = potential_doc.data.decode('latin-1')\n",
    "            doc = TwoDDoc.from_code(raw_data)\n",
    "        except Exception as e:\n",
    "            # not a 2d-doc\n",
    "            # print(\"exception\", e)\n",
    "            continue\n",
    "\n",
    "    if doc is None:\n",
    "        # print(\"no valid 2d-doc found\")\n",
    "        return None\n",
    "\n",
    "    # Mapping from French field names to English attributes\n",
    "    field_mapping = {\n",
    "        \"Nombre de parts\": \"number_of_shares\",\n",
    "        \"Référence d'avis d'impôt\": \"tax_notice_reference\",\n",
    "        \"Année des revenus\": \"income_year\",\n",
    "        \"Déclarant 1\": \"declarant_1\",\n",
    "        \"Date de mise en recouvrement\": \"collection_date\",\n",
    "        \"Numéro fiscal du déclarant 1\": \"tax_number_declarant_1\",\n",
    "        \"Revenu fiscal de référence\": \"reference_tax_income\",\n",
    "    }\n",
    "    \n",
    "    # Extract data\n",
    "    data = {\n",
    "        \"doc_type\": doc.header.doc_type().user_type if hasattr(doc.header.doc_type(), 'user_type') else None,\n",
    "        \"emitter_type\": doc.header.doc_type().emitter_type if hasattr(doc.header.doc_type(), 'emitter_type') else None,\n",
    "    }\n",
    "    \n",
    "    # Extract fields from dataset\n",
    "    for item in doc.message.dataset:\n",
    "        field_name = item.definition.name\n",
    "        if field_name in field_mapping:\n",
    "            data[field_mapping[field_name]] = str(item.value)\n",
    "    \n",
    "    return TaxNoticeData(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744efc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_tax_notice_dataset()\n",
    "\n",
    "def debug_tax_notice(result: TaxNoticeData):\n",
    "    print(f\"  Doc Type: {result.doc_type}\")\n",
    "    print(f\"  Emitter Type: {result.emitter_type}\")\n",
    "    print(f\"  Tax Notice Reference: {result.tax_notice_reference}\")\n",
    "    print(f\"  Income Year: {result.income_year}\")\n",
    "    print(f\"  Declarant 1: {result.declarant_1}\")\n",
    "    print(f\"  Tax Number: {result.tax_number_declarant_1}\")\n",
    "    print(f\"  Reference Tax Income: {result.reference_tax_income}\")\n",
    "    print(f\"  Collection Date: {result.collection_date}\")\n",
    "    print(f\"  Number of Shares: {result.number_of_shares}\")\n",
    "\n",
    "def _worker(file_id: str):\n",
    "    \"\"\"\n",
    "    Worker executed in a separate process.\n",
    "    Returns (file_id, ok:bool, image_bytes or None, tax_notice_dict or None)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = get_tax_notice_image(file_id)\n",
    "        tax_notice = extract_tax_notice(img, timeout=5000) # give the lib 20s\n",
    "        if tax_notice:\n",
    "            buf = BytesIO()\n",
    "            # use PNG to be safe for all input types\n",
    "            img.save(buf, format=\"PNG\")\n",
    "            return (file_id, True, buf.getvalue(), tax_notice.model_dump())\n",
    "        return (file_id, False, None, None)\n",
    "    except Exception:\n",
    "        return (file_id, False, None, None)\n",
    "\n",
    "\n",
    "def save_tax_results(tax_results, output_path=\"tax_results.csv\"):\n",
    "    df = pd.DataFrame([\n",
    "        {\"file_id\": fid, **tax_dict}\n",
    "        for fid, tax_dict in tax_results.items()\n",
    "    ])\n",
    "    mode = \"a\" if os.path.exists(output_path) else \"w\"\n",
    "    header = not os.path.exists(output_path)\n",
    "    df.to_csv(output_path, mode=mode, header=header, index=False)\n",
    "\n",
    "valid_content = []\n",
    "tax_results = {}  # map file_id -> tax dict\n",
    "\n",
    "dataset_subset = dataset#[:100]\n",
    "output_path = \"../../datasets/2d-doc/tax-notices-extracted-2d-doc.csv\"\n",
    "batch_size_save = 100\n",
    "pending = {}\n",
    "counter = 0\n",
    "\n",
    "# run up to 20 processes concurrently, one process per file_id\n",
    "with ProcessPoolExecutor(max_workers=20) as exe:\n",
    "    futures = {exe.submit(_worker, fid): fid for fid in dataset_subset}\n",
    "\n",
    "    with tqdm(total=len(dataset_subset), desc=\"Processing tax notices\", unit=\"file\") as pbar:\n",
    "        for fut in as_completed(futures):\n",
    "            file_id = futures[fut]\n",
    "            try:\n",
    "                file_id, ok, img_bytes, tax_dict = fut.result()\n",
    "            except Exception:\n",
    "                ok, img_bytes, tax_dict = False, None, None\n",
    "\n",
    "            pbar.set_postfix({\"success\": \"✓\" if ok else \"✗\"})\n",
    "            pbar.update(1)\n",
    "\n",
    "            if ok:\n",
    "                pending[file_id] = tax_dict\n",
    "                counter += 1\n",
    "\n",
    "            # ✅ write after every full batch, outside the executor loop\n",
    "            if counter and counter % batch_size_save == 0:\n",
    "                # temporarily copy to avoid modifying while writing\n",
    "                to_save = pending.copy()\n",
    "                pending.clear()\n",
    "                save_tax_results(to_save, output_path)\n",
    "\n",
    "# final flush\n",
    "if pending:\n",
    "    save_tax_results(pending, output_path)\n",
    "\n",
    "success_count = len(valid_content)\n",
    "total_count = len(dataset_subset)\n",
    "print(f\"\\n✓ Successfully processed: {success_count}/{total_count} ({100*success_count/total_count:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b380e",
   "metadata": {},
   "source": [
    "# debug / tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e40757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see some valid_content\n",
    "for file_id, data in valid_content[:10]:\n",
    "    tax_notice = TaxNoticeData(**data)\n",
    "    print(file_id)\n",
    "    debug_tax_notice(tax_notice)\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check specific tax_id\n",
    "tax_id = \"xx xxx xxx\"\n",
    "tax_image = get_tax_notice_image(tax_id)#.convert(\"RGB\")\n",
    "x = extract_tax_notice(tax_image, timeout=10000)\n",
    "print(x)\n",
    "tax_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see few documents where no 2d-doc have been identified\n",
    "valid_ids = [fid for fid, _ in valid_content]\n",
    "invalid_ids = [fid for fid in dataset if fid not in valid_ids]\n",
    "len(invalid_ids)\n",
    "for invalid_id in invalid_ids[:20]:\n",
    "    image = get_tax_notice_image(invalid_id)\n",
    "    print(invalid_id)\n",
    "    display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document-ia",
   "language": "python",
   "name": "document-ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
